'''
name: run_sundial2predict.py
usage: predict 2025 tep by Sundial
imput: /root/autodl-tmp/project/mlpj/data/processed/shanghai_2010_2025_full.npy
       /root/autodl-tmp/project/mlpj/data/processed/shanghai_2010_2025.csv
output: /root/autodl-tmp/project/mlpj/results/logs/eval_2025_standard_results.npz
authors/date: Q/2025.12.14
'''
import os
import random
import torch
import numpy as np
import pandas as pd
from transformers import AutoModelForCausalLM
# å¼•å…¥æ ‡å‡†åŒ–æ‰€éœ€çš„åº“
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tqdm import tqdm

# è®¾ç½®å›½å†…é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# ================= 0. æ ‡å‡†åŒ–åè®®ï¼šéšæœºç§å­ =================
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"[Protocol] Random Seed set to {seed}")

set_seed(42)  # é”å®šéšæœºæ€§

# ================= 1. é…ç½®åŒºåŸŸ =================
model_path = "/root/autodl-tmp/models/sundial-base-128m"
data_npy = "/root/autodl-tmp/project/mlpj/data/processed/shanghai_2010_2025_full.npy"
data_csv = "/root/autodl-tmp/project/mlpj/data/processed/shanghai_2010_2025.csv"

# æ ‡å‡†åŒ–å‚æ•°
context_len = 512
pred_len = 24
stride = 24

# ================= 2. æ•°æ®åŠ è½½ä¸æ ‡å‡†åŒ–é¢„å¤„ç† =================
print("1. [Protocol] Loading & Preprocessing Data...")
if not os.path.exists(data_npy) or not os.path.exists(data_csv):
    print("âŒ Data not found.")
    exit()

# åŠ è½½åŸå§‹æ•°æ®
data_values = np.load(data_npy) # (N,)
if data_values.ndim == 1:
    data_values = data_values.reshape(-1, 1) # ç¡®ä¿æ˜¯ (N, 1)

df = pd.read_csv(data_csv)
df['time'] = pd.to_datetime(df['time'])

# --- ä¸¥æ ¼åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›† ---
split_date = pd.Timestamp("2025-01-01 00:00:00")
train_mask = df['time'] < split_date

# è®­ç»ƒé›†: 2010-2024
train_data_raw = data_values[train_mask]

# æµ‹è¯•èµ·ç‚¹ç´¢å¼•
test_start_idx = np.sum(train_mask)
print(f"   -> Train Data End: {df['time'].iloc[test_start_idx-1]}")
print(f"   -> Test Start:     {df['time'].iloc[test_start_idx]}")

# --- ç»Ÿä¸€é¢„å¤„ç†: MinMaxScaler (0~1) ---
# è§„åˆ™: åªèƒ½ç”¨è®­ç»ƒé›†(2010-2024) fitï¼Œé˜²æ­¢æœªæ¥æ•°æ®æ³„éœ²
scaler = MinMaxScaler(feature_range=(0, 1))
scaler.fit(train_data_raw)

# è½¬æ¢å…¨é‡æ•°æ®
data_scaled = scaler.transform(data_values).flatten() # (N,)
print(f"   -> [Protocol] Scaler fitted on Train set (2010-2024).")
print(f"   -> Scaled Data Range: {data_scaled.min():.3f} ~ {data_scaled.max():.3f}")

# ================= 3. åŠ è½½æ¨¡å‹ =================
print("2. Loading Model...")
device = "cuda" if torch.cuda.is_available() else "cpu"
try:
    if os.path.exists(model_path):
        model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True).to(device)
    else:
        model = AutoModelForCausalLM.from_pretrained("thuml/sundial-base-128m", trust_remote_code=True).to(device)
    model.eval()
    print(f"   âœ… Model loaded on {device}")
except Exception as e:
    print(f"âŒ Load failed: {e}")
    exit()

# ================= 4. æ»šåŠ¨é¢„æµ‹ (Standard Rolling) =================
print(f"3. [Protocol] Rolling Forecast (Stride={stride})...")

all_preds = []
all_trues = []
timestamps = []

# è¿­ä»£å™¨: ä» 2025-01-01 å¼€å§‹
idx_iter = range(test_start_idx, len(data_values) - pred_len, stride)

for current_idx in tqdm(idx_iter, desc="Inferencing"):
    # A. å‡†å¤‡è¾“å…¥ (ä»å…¨å±€å½’ä¸€åŒ–åçš„æ•°æ®ä¸­å–)
    # è§„åˆ™: ç›´æ¥å– data_scaledï¼Œä¸å†åšå±€éƒ¨å½’ä¸€åŒ–
    history_norm = data_scaled[current_idx - context_len : current_idx]
    
    input_tensor = torch.tensor(history_norm, dtype=torch.float32).unsqueeze(0).to(device)
    
    # B. æ¨¡å‹æ¨ç†
    with torch.no_grad():
        # å›ºå®šé‡‡æ ·è¡Œä¸º (è™½ç„¶è®¾ç½®äº†seedï¼Œä½†æ˜¾å¼æ§åˆ¶æ›´å®‰å…¨)
        # Sundial æ˜¯ç”Ÿæˆæ¨¡å‹ï¼Œè¿™é‡Œä¸ºäº†ç¨³å®šå– 3 æ¬¡ä¸­ä½æ•°
        batch_preds = []
        for _ in range(3):
            output = model.generate(input_tensor, max_new_tokens=pred_len, num_samples=1)
            pred_slice = output[:, -pred_len:]
            batch_preds.append(pred_slice.cpu().numpy())
        
        # å¾—åˆ°å½’ä¸€åŒ–åçš„é¢„æµ‹å€¼ (0~1ä¹‹é—´)
        pred_norm = np.median(np.array(batch_preds), axis=0).flatten()
    
    # C. è·å–çœŸå®å€¼ (å½’ä¸€åŒ–åçš„)
    true_norm = data_scaled[current_idx : current_idx + pred_len]
    
    # D. åå½’ä¸€åŒ– (Inverse Transform)
    # è§„åˆ™: ä½¿ç”¨å…¨å±€ Scaler è¿˜åŸ
    pred_real = scaler.inverse_transform(pred_norm.reshape(-1, 1)).flatten()
    true_real = scaler.inverse_transform(true_norm.reshape(-1, 1)).flatten()
    
    all_preds.extend(pred_real)
    all_trues.extend(true_real)
    timestamps.extend(df['time'].iloc[current_idx : current_idx + pred_len])

all_preds = np.array(all_preds)
all_trues = np.array(all_trues)

# ================= 5. è®¡ç®—æŒ‡æ ‡ (Standard Metrics) =================
mse = mean_squared_error(all_trues, all_preds)
mae = mean_absolute_error(all_trues, all_preds)
rmse = np.sqrt(mse)
r2 = r2_score(all_trues, all_preds)

print("\n" + "="*40)
print(f"ğŸ“Š 2025 Evaluation Report (Standard Protocol):")
print(f"   MAE  : {mae:.4f} Â°C")
print(f"   RMSE : {rmse:.4f} Â°C")
print(f"   MSE  : {mse:.4f}")
print(f"   RÂ²   : {r2:.4f}")
print("="*40)

# ================= 6. ä¿å­˜ç»“æœ =================
save_path = "/root/autodl-tmp/project/mlpj/results/logs/eval_2025_standard_results.npz"
np.savez(save_path, preds=all_preds, trues=all_trues, mse=mse, mae=mae, rmse=rmse, r2=r2)
print(f"ğŸ’¾ Results saved to {save_path}")
