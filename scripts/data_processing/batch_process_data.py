'''
name: batch_process_data.py
usage: å¤„ç†æ•°æ®
'''
import xarray as xr
import numpy as np
import pandas as pd
import os
import glob
from tqdm import tqdm

# ================= é…ç½® =================
source_dir = "/root/autodl-tmp/project/mlpj/data/raw/era5_full_feat" 

output_dir = "/root/autodl-tmp/project/mlpj/data/processed"
os.makedirs(output_dir, exist_ok=True)

def process_years(years, save_name):
    print(f"\nğŸš€ æ­£åœ¨å¤„ç†å¹´ä»½: {years} -> {save_name}")
    files = []
    for y in years:
        # æœç´¢è¯¥å¹´ä»½çš„æ‰€æœ‰ nc æ–‡ä»¶
        found = glob.glob(os.path.join(source_dir, f"*{y}*.nc"))
        files.extend(found)
    
    files = sorted(files)
    if not files:
        print(f"   âŒ æœªæ‰¾åˆ°å¹´ä»½ {years} çš„æ–‡ä»¶ï¼Œè·³è¿‡ï¼")
        return

    print(f"   -> æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æå–ç‰¹å¾...")
    
    all_data = []
    timestamps = []
    
    for f in tqdm(files):
        try:
            ds = xr.open_dataset(f, engine="h5netcdf")
            
            # --- æå– 7 å¤§ç‰¹å¾ ---
            # 1. æ°”æ¸© (K -> C)
            t2m = ds['t2m'].mean(dim=['latitude', 'longitude']).values - 273.15
            # 2. éœ²ç‚¹ (K -> C)
            d2m = ds['d2m'].mean(dim=['latitude', 'longitude']).values - 273.15
            # 3. é™é›¨ (m -> mm)
            tp  = ds['tp'].mean(dim=['latitude', 'longitude']).values * 1000
            # 4. æ°”å‹ (Pa -> hPa)
            sp  = ds['sp'].mean(dim=['latitude', 'longitude']).values / 100
            # 5. è¾å°„ (J/m2)
            ssrd= ds['ssrd'].mean(dim=['latitude', 'longitude']).values
            # 6. åœŸå£¤æ°´ (0-1)
            swvl1=ds['swvl1'].mean(dim=['latitude', 'longitude']).values
            # 7. é£é€Ÿ (åˆæˆ m/s)
            u10 = ds['u10'].mean(dim=['latitude', 'longitude']).values
            v10 = ds['v10'].mean(dim=['latitude', 'longitude']).values
            wind = np.sqrt(u10**2 + v10**2)
            
            # å †å  (Time, 7)
            batch = np.stack([t2m, d2m, tp, sp, ssrd, swvl1, wind], axis=1)
            all_data.append(batch)
            
            # ç”Ÿæˆæ—¶é—´è½´ (è¾…åŠ©)
            # ç®€å•ç”Ÿæˆ: å‡è®¾æ¯ä¸ªæ–‡ä»¶æ˜¯ä¸€ä¸ªæœˆ
            # è¿™é‡Œä¸ç›´æ¥è¯» ds.time å› ä¸ºæ ¼å¼å¯èƒ½ä¹±ï¼Œæˆ‘ä»¬åé¢ç»Ÿä¸€ç”Ÿæˆ
            
            ds.close()
        except Exception as e:
            print(f"   âš ï¸ è¯»å–å¤±è´¥ {os.path.basename(f)}: {e}")

    if all_data:
        full_arr = np.concatenate(all_data, axis=0)
        save_path = os.path.join(output_dir, save_name)
        np.save(save_path, full_arr)
        print(f"   âœ… ä¿å­˜æˆåŠŸ: {save_path} | Shape: {full_arr.shape}")
        
        # ä¿å­˜ä¸€ä»½ CSV æ–¹ä¾¿æŸ¥æ—¶é—´
        # å‡è®¾æ•°æ®æ˜¯è¿ç»­çš„ï¼Œæˆ‘ä»¬æ ¹æ®é•¿åº¦åæ¨æ—¶é—´
        start_year = years[0]
        dates = pd.date_range(start=f'{start_year}-01-01', periods=len(full_arr), freq='H')
        df = pd.DataFrame(full_arr, columns=['t2m', 'd2m', 'tp', 'sp', 'ssrd', 'swvl1', 'wind'])
        df.insert(0, 'time', dates)
        csv_path = save_path.replace('.npy', '.csv')
        df.to_csv(csv_path, index=False)
        print(f"   âœ… CSV å·²ä¿å­˜: {csv_path}")

# ================= æ‰§è¡Œå¤„ç† =================
# 1. è®­ç»ƒé›†: 2010, 2011, 2012, 2013, 2014
train_years = [str(y) for y in range(2010, 2015)]
process_years(train_years, "train_2010_2014_rich.npy")

# 2. æµ‹è¯•é›†: 2025
test_years = ["2025"]
process_years(test_years, "test_2025_rich.npy")
